<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Storing Flink savepoint and artifacts in AWS S3 &#8211; Blog of software writer Chee Yeo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Using AWS S3 to store artifacts and savepoints">
    <meta name="author" content="Chee Yeo">
    <meta name="keywords" content="datascience, beam, flink, pyflink, kubernetes, kind, aws, s3">
    <link rel="canonical" href="https://www.cheeyeo.dev/datascience/beam/flink/pyflink/kubernetes/kind/aws/s3/2022/11/10/flink-s3/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Blog of software writer Chee Yeo" href="/feed.xml" />
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?202211231740" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_UK">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Storing Flink savepoint and artifacts in AWS S3">
    <meta property="og:description" content="Chee Yeo is a software developer with interests in machine learning and cloud computing.">
    <meta property="og:url" content="https://www.cheeyeo.dev/datascience/beam/flink/pyflink/kubernetes/kind/aws/s3/2022/11/10/flink-s3/">
    <meta property="og:site_name" content="Blog of software writer Chee Yeo">
</head>

<body class="">
  <div class="color-line"></div>
  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      
        <nav class="site-nav">
          <a href="/">Home</a>
          <a href="https://tilrnt.github.io/" target="_blank">TILRNT</a>
          <a href="/about">About</a>
          <a href="/contact">Contact</a>
        </nav>
      
      <div class="clearfix"></div>
    </div>
  </div>
</header>

    <header class="blog-header">
  <h1 class="blog-title">Storing Flink savepoint and artifacts in AWS S3</h1>

  
  <div class="meta_info">
    
    <div class="author-date-wrap">
      <div class="author">
        <a href="/about">Chee Yeo</a>
      </div>
    </div>
    
    <span class="post-date">November 10, 2022</span>
    
    <ul class="article-tag">
      
      <li>
        <a href="/categories/datascience">datascience</a>
      </li>
      
      <li>
        <a href="/categories/beam">beam</a>
      </li>
      
      <li>
        <a href="/categories/flink">flink</a>
      </li>
      
      <li>
        <a href="/categories/pyflink">pyflink</a>
      </li>
      
      <li>
        <a href="/categories/kubernetes">kubernetes</a>
      </li>
      
      <li>
        <a href="/categories/kind">kind</a>
      </li>
      
      <li>
        <a href="/categories/aws">aws</a>
      </li>
      
      <li>
        <a href="/categories/s3">s3</a>
      </li>
      
    </ul>
    
  </div>
  
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<article class="post-content top-border">
  
<p>We can run jobs in Flink in either Batch mode or Streaming mode. In streaming mode, we are able to save the state of the job in a specified interval. This allows for the job to resume from a given state in case of failure. These saved states are known as <strong>savepoints</strong></p>

<p>A thorough discussion on the subject is beyond the scope of this post so I refer the avid reader to the <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/savepoints">Flink guide on savepoints</a>.</p>

<p>An important distinction is that <strong>savepoints</strong> are different from <strong>checkpoints</strong> in the sense that the former requires user intervention while the latter is invoked by the flink cluster through for example in HA (High Availability) mode.</p>

<p>An important thing to note is that savepoints can only be invoked for streaming jobs; it won’t work for batch jobs.</p>

<p>In order to test such a functionality with the Flink Operator, we use the <a href="https://github.com/spotify/flink-on-k8s-operator/blob/master/docs/kafka_test_guide.md">Kafka test guide</a> example, which provides a streaming example using kafka pipelines.</p>

<p>The rest of this post assumes you have a running <code class="language-plaintext highlighter-rouge">kind</code> cluster with the <code class="language-plaintext highlighter-rouge">flink operator</code> installed. If not, please refer to the previous posts on the subject.</p>

<p>The following steps detail how to use such an image in a streaming job running in a kubernetes cluster locally via the flink operator:</p>

<h3 id="1-build-the-kafka-example">1. Build the kafka example</h3>

<p>We need to clone the <a href="https://github.com/apache/flink-playgrounds/tree/master/docker/data-generator">Flink playground example</a> and make the following changes to the Dockerfile:</p>

<figure class="highlight"><pre><code class="language-docker" data-lang="docker"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre><span class="c">###############################################################################</span>
<span class="c"># Build Operations Playground Image</span>
<span class="c">###############################################################################</span>

<span class="k">FROM</span><span class="s"> apache/flink:1.15.2-scala_2.12-java8</span>

<span class="k">WORKDIR</span><span class="s"> /opt/flink/bin</span>

<span class="c"># Copy s3 plugins</span>
<span class="k">RUN </span><span class="nb">cd</span> ../ <span class="o">&amp;&amp;</span> <span class="se">\
</span>    <span class="nb">mkdir</span> <span class="nt">-p</span> plugins/s3-fs-hadoop <span class="o">&amp;&amp;</span> <span class="se">\
</span>    <span class="nb">cp </span>opt/flink-s3-fs-hadoop-1.15.2.jar plugins/s3-fs-hadoop

<span class="c"># Copy Click Count Job</span>
<span class="k">COPY</span><span class="s"> --from=builder /opt/flink-playground-clickcountjob/target/flink-playground-clickcountjob-*.jar /opt/ClickCountJob.jar</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>To save <code class="language-plaintext highlighter-rouge">savepoints</code> to remote cloud storage such as S3, we need to enable the filestorage plugins within the <code class="language-plaintext highlighter-rouge">apache/flink</code> image. This is done by copying the <code class="language-plaintext highlighter-rouge">/opt/flink/opt/flink-s3-fs-hadoop-1.15.2.jar</code> into its own plugin directory of <code class="language-plaintext highlighter-rouge">/opt/flink/plugins/flink-s3-fs-hadoop-1.15.2.jar</code></p>

<p>Once the custom image is built we can load it into the kind cluster</p>

<h3 id="2-install-kafka">2. Install kafka</h3>

<p>Next we need to install the <code class="language-plaintext highlighter-rouge">helm</code> repo for the <code class="language-plaintext highlighter-rouge">kafka</code> cluster. The following script is adapted from <a href="https://github.com/spotify/flink-on-k8s-operator/blob/master/docs/kafka_test_guide.md">Kafka test guide</a>:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="code"><pre>kubectl create ns kafka

helm repo add incubator https://charts.helm.sh/incubator

helm <span class="nb">install </span>my-kafka incubator/kafka <span class="nt">--namespace</span> kafka

helm status my-kafka <span class="nt">-n</span> kafka
</pre></td></tr></tbody></table></code></pre></figure>

<p>Make the script executable and run it. Check that the namespace has the pods running.</p>

<h3 id="3-create-the-deployment">3. Create the deployment</h3>

<p>We need to create a generator deployment that writes data to the kafka cluster. This is adopted from the <a href="https://github.com/spotify/flink-on-k8s-operator/blob/master/docs/kafka_test_guide.md">Kafka test guide</a>:</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="code"><pre><span class="c1"># Example from the flink playground</span>
<span class="c1"># Deployment that writes data to kafka cluster</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">kafka-click-generator</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">kafka-click-generator</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">kafka-click-generator</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">kafka-click-generator</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">m1l0/flink-ops-playground:1.15.2-scala_2.12</span>
          <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">java"</span><span class="pi">]</span>
          <span class="na">args</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">-classpath"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">/opt/ClickCountJob.jar:/opt/flink/lib/*"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">org.apache.flink.playgrounds.ops.clickcount.ClickEventGenerator"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">--bootstrap.servers"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">my-kafka.kafka.svc.cluster.local:9092"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">--topic"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">input"</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>Note that we are using our own custom image built in step 1.</p>

<p>Create the deployment and check that the pods are running.</p>

<h3 id="4-create-the-consumer">4. Create the consumer</h3>

<p>The consumer of the data stream is a flink operator job that runs the <code class="language-plaintext highlighter-rouge">ClickCount.jar</code> application that consumes data from the kafka stream.</p>

<p>The job is deployed as a standalone application cluster via the flink operator.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">flinkoperator.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">FlinkCluster</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">clickcount</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">flinkVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1.15.2"</span>
  <span class="na">image</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">m1l0/flink-ops-playground:1.15.2-scala_2.12</span>
    <span class="na">pullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
  <span class="na">jobManager</span><span class="pi">:</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="na">ui</span><span class="pi">:</span> <span class="m">8081</span>
    <span class="na">resources</span><span class="pi">:</span>
      <span class="na">limits</span><span class="pi">:</span>
        <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2Gi"</span>
        <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">200m"</span>
  <span class="na">taskManager</span><span class="pi">:</span>
    <span class="na">replicas</span><span class="pi">:</span> <span class="m">2</span>
    <span class="na">resources</span><span class="pi">:</span>
      <span class="na">limits</span><span class="pi">:</span>
        <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2Gi"</span>
        <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">200m"</span>
  <span class="na">envVars</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">ENABLE_BUILT_IN_PLUGINS</span>
    <span class="na">value</span><span class="pi">:</span> <span class="s">flink-s3-fs-hadoop-1.15.2.jar;</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">AWS_ACCESS_KEY_ID</span>
    <span class="na">valueFrom</span><span class="pi">:</span>
      <span class="na">secretKeyRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">flink-aws-secret</span>
        <span class="na">key</span><span class="pi">:</span> <span class="s">access_key_id</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">AWS_SECRET_ACCESS_KEY</span>
    <span class="na">valueFrom</span><span class="pi">:</span>
      <span class="na">secretKeyRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">flink-aws-secret</span>
        <span class="na">key</span><span class="pi">:</span> <span class="s">secret_access_key</span>
  <span class="na">job</span><span class="pi">:</span>
    <span class="na">jarFile</span><span class="pi">:</span> <span class="s">/opt/ClickCountJob.jar</span>
    <span class="na">className</span><span class="pi">:</span> <span class="s">org.apache.flink.playgrounds.ops.clickcount.ClickEventCount</span>
    <span class="na">args</span><span class="pi">:</span>
      <span class="pi">[</span>
        <span class="s2">"</span><span class="s">--bootstrap.servers"</span><span class="pi">,</span>
        <span class="s2">"</span><span class="s">my-kafka.kafka.svc.cluster.local:9092"</span><span class="pi">,</span>
        <span class="s2">"</span><span class="s">--checkpointing"</span><span class="pi">,</span>
        <span class="s2">"</span><span class="s">--event-time"</span><span class="pi">,</span>
      <span class="pi">]</span>
    <span class="na">parallelism</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">savepointsDir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">s3a://flinkexps/savepoints"</span>
    <span class="na">autoSavepointSeconds</span><span class="pi">:</span> <span class="m">10</span>
  <span class="na">flinkProperties</span><span class="pi">:</span>
    <span class="na">taskmanager.numberOfTaskSlots</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1"</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>There are several important things to note here.</p>

<p>The <code class="language-plaintext highlighter-rouge">ENABLE_BUILT_IN_PLUGINS</code> is <strong>required</strong> to allow the plugins to be copied over to the client else the job will fail with plugins not found error.</p>

<p>The <code class="language-plaintext highlighter-rouge">AWS_ACCESS_KEY_ID</code> and <code class="language-plaintext highlighter-rouge">AWS_SECRET_ACCESS_KEY_ID</code> are fetched from a kubernetes secret and mounted as env vars within the job container.</p>

<p>Within the job spec we need to declare the following 2 properties to allow for automatic savepoint creation via the flink operator.</p>

<p>The <code class="language-plaintext highlighter-rouge">savePointsDir</code> is the target location of our savepoints. Note that the file system prefix is <strong>s3a</strong> as we are using the hadoop filesystem integration and it only works with that prefix.</p>

<p>We also need to declare <code class="language-plaintext highlighter-rouge">autoSavepointSeconds</code> which is a non-negative integer which specifies how often to create a savepoint. In this example we set it to a lower/frequent interval of 10secs to test if it works.</p>

<p>Apply the above configuration and check the status of the job submitted via:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre>kubectl describe flinkcluster clickcount
</pre></td></tr></tbody></table></code></pre></figure>

<p>If all goes well, after 10 seconds, you should see a stream of savepoints being created</p>

<p><img src="/assets/img/flink/savepoints/cli.png" alt="Flink Application CLI" />
<img src="/assets/img/flink/savepoints/console.png" alt="AWS S3 console" /></p>

<h3 id="5-triggering-savepoints">5. Triggering savepoints</h3>

<p>You can also trigger the manual creation of savepoints as highlighted in the <a href="https://github.com/spotify/flink-on-k8s-operator/blob/master/docs/savepoints_guide.md">Flink operator savepoints guide</a>. Of all the approaches listed, the easiest one I found to work for me was to <strong>annotate</strong> the cluster manually.</p>

<p>For example, given the flinkcluster resource above, I can run:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre>kubectl annotate flinkclusters clickcount flinkclusters.flinkoperator.k8s.io/user-control<span class="o">=</span>savepoint
</pre></td></tr></tbody></table></code></pre></figure>

<p>You should see the message <code class="language-plaintext highlighter-rouge">User control savepoint triggered</code> event message and the savepoint shown under the job specs.</p>

<h4 id="saving-artifacts">Saving artifacts</h4>

<p>To save artifacts to S3 from batch jobs, we need to do the same as above:</p>

<ul>
  <li>Create a custom image where we copy over the hadoop s3 plugins</li>
  <li>Create and mount the env vars</li>
  <li>Specify the target s3 bucket with <strong>s3a</strong> prefix</li>
</ul>

<p>Below is an example of a batch job submitted to the flink operator:</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">flinkoperator.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">FlinkCluster</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pyflink-wordcount</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">flinkVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1.15.2"</span>
  <span class="na">image</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">m1l0/pyflink:1.15.2-scala_2.12</span>
    <span class="na">pullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
  <span class="na">taskManager</span><span class="pi">:</span>
    <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
    <span class="c1"># Below is needed to access attached volumes as flink user</span>
    <span class="na">securityContext</span><span class="pi">:</span>
      <span class="na">runAsUser</span><span class="pi">:</span> <span class="m">9999</span>
      <span class="na">runAsGroup</span><span class="pi">:</span> <span class="m">9999</span>
      <span class="na">fsGroup</span><span class="pi">:</span> <span class="m">9999</span>
  <span class="na">envVars</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">ENABLE_BUILT_IN_PLUGINS</span>
    <span class="na">value</span><span class="pi">:</span> <span class="s">flink-s3-fs-hadoop-1.15.2.jar;</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">AWS_ACCESS_KEY_ID</span>
    <span class="na">valueFrom</span><span class="pi">:</span>
      <span class="na">secretKeyRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">flink-aws-secret</span>
        <span class="na">key</span><span class="pi">:</span> <span class="s">access_key_id</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">AWS_SECRET_ACCESS_KEY</span>
    <span class="na">valueFrom</span><span class="pi">:</span>
      <span class="na">secretKeyRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">flink-aws-secret</span>
        <span class="na">key</span><span class="pi">:</span> <span class="s">secret_access_key</span>
  <span class="na">job</span><span class="pi">:</span>
    <span class="na">pyFile</span><span class="pi">:</span> <span class="s2">"</span><span class="s">examples/python/datastream/word_count.py"</span>
    <span class="na">args</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">--output"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">s3a://flinkexps/artifacts/pyflink/"</span><span class="pi">]</span>
    <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
  <span class="na">flinkProperties</span><span class="pi">:</span>
    <span class="na">s3.path.style.access</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>The above runs an example pyflink job provided in the Flink docker image which we customized by copying over the hadoop plugins. Note that the same env vars as specified for streaming jobs must be present for it to work in batch mode.</p>

<h3 id="summary">Summary</h3>

<p>This post attempts to explain how to create and store savepoints in remote cloud storage either through running a streaming job or as the artifacts of a batch job.</p>

<p>In the next posts, I will attempt to cover checkpoints and the high availability mode in a flink cluster.</p>

<p>H4ppy H4ck1n6 !!!</p>

</article>





      </div>
    </div>
  </div>

  <footer class="footer">
  <div class="p2 wrap">
    
      <div class="social-icons">
  <div class="">
    
      <a class="fa fa-github fa-lg" href="https://github.com/cheeyeo" target="_blank"></a>
    
    <a class="fa fa-rss fa-lg" href="https://www.cheeyeo.dev/feed.xml" target="_blank"></a>
    
    
    
      <a class="fa fa-envelope fa-lg" href="mailto:f/mnqwaypk"></a>
    
    
      <a class="fa fa-linkedin fa-lg" href="https://www.linkedin.com/in/cheeyeo" target="_blank"></a>
    
  </div>
</div>

    

    <div class="measure mt1 center">
      <strong>© 2022 Chee Yeo</strong><br/>
      <small>
        Built using the Pixll theme available on <a href="https://github.com/johno/pixyll" target="_blank">Github</a>.
      </small>
    </div>
  </div>
</footer>



</body>
</html>
