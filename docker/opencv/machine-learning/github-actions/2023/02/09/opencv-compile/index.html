<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Compiling OpenCV &#8211; Blog of software writer Chee Yeo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="How to manually compile opencv using nvidia deep learning containers for fun and profit">
    <meta name="author" content="Chee Yeo">
    <meta name="keywords" content="docker, opencv, machine-learning, github-actions">
    <link rel="canonical" href="https://www.cheeyeo.dev/docker/opencv/machine-learning/github-actions/2023/02/09/opencv-compile/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Blog of software writer Chee Yeo" href="/feed.xml" />
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?202302141635" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_UK">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Compiling OpenCV">
    <meta property="og:description" content="Chee Yeo is a software developer with interests in machine learning and cloud computing.">
    <meta property="og:url" content="https://www.cheeyeo.dev/docker/opencv/machine-learning/github-actions/2023/02/09/opencv-compile/">
    <meta property="og:site_name" content="Blog of software writer Chee Yeo">
</head>

<body class="">
  <div class="color-line"></div>
  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      
        <nav class="site-nav">
          <a href="/">Home</a>
          <a href="https://tilrnt.github.io/" target="_blank">TILRNT</a>
          <a href="/about">About</a>
          <a href="/contact">Contact</a>
        </nav>
      
      <div class="clearfix"></div>
    </div>
  </div>
</header>

    <header class="blog-header">
  <h1 class="blog-title">Compiling OpenCV</h1>

  
  <div class="meta_info">
    
    <div class="author-date-wrap">
      <div class="author">
        <a href="/about">Chee Yeo</a>
      </div>
    </div>
    
    <span class="post-date">February 9, 2023</span>
    
    <ul class="article-tag">
      
      <li>
        <a href="/categories/docker">docker</a>
      </li>
      
      <li>
        <a href="/categories/opencv">opencv</a>
      </li>
      
      <li>
        <a href="/categories/machine-learning">machine-learning</a>
      </li>
      
      <li>
        <a href="/categories/github-actions">github-actions</a>
      </li>
      
    </ul>
    
  </div>
  
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<article class="post-content top-border">
  
<p>In a former project, I attempted to automate the process of building base docker images for machine learning projects. In this post, I will attempt to explain the approach I took for automating the process of building computer vision projects.</p>

<p>OpenCV is a library commonly used in computer vision tasks. You can run <code class="language-plaintext highlighter-rouge">pip install opencv-contrib</code> to download the latest python packages and this would be adequate for most learning tasks. However, to utilise some of its advanced features such as the <strong>dnn</strong> module which enables one to import and run pre-trained models from other frameworks, you would need to manually compile OpenCV. This would also involve compiling it with the required CUDA / CUDNN libraries.</p>

<p>The overall criteria of the build process becomes:</p>
<ul>
  <li>
    <p>The image would need to support both python bindings and C++ libraries.</p>
  </li>
  <li>
    <p>The image would need to have the required CUDA/CUDNN Libs installed in order to use <code class="language-plaintext highlighter-rouge">dnn</code></p>
  </li>
  <li>
    <p>The image would need to be as compact as possible to only include the required libraries due to size constraint.</p>
  </li>
</ul>

<p>I decided to split the images into 2 categories: the plain CPU build and the GPU build.</p>

<p>The GPU build process is a <strong>multi-stage build</strong></p>

<p>The GPU build is specified in a separate Dockerfile and makes use of the following <a href="https://docs.nvidia.com/deeplearning/frameworks/user-guide/index.html">NVIDIA Deep Learning Containers</a>:</p>

<ul>
  <li>nvidia/cuda:${CUDA}-cudnn8-devel-ubuntu${UBUNTU}</li>
  <li>nvidia/cuda:${CUDA}-cudnn8-runtime-ubuntu${UBUNTU}</li>
</ul>

<p>According to the documentation, the nvidia images are organized into the following categories:</p>

<ul>
  <li>
    <p><strong>base</strong></p>

    <p>Base image which is built on by other image types</p>
  </li>
  <li>
    <p><strong>devel</strong>
For development as it contains the necessary compilers and libraries to build applications. Images in this category are big. For example, the <code class="language-plaintext highlighter-rouge">11.8.0-cudnn8-devel-ubuntu22.04</code> has a size of 8.99 GB uncompressed.</p>
  </li>
  <li>
    <p><strong>runtime</strong></p>

    <p>For deploying complied applications. This image would only contain the required libraries but without the compilation tools of the devel images, making it smaller in size.</p>
  </li>
</ul>

<p>The <strong>cudnn8-devel</strong> images include the CUDNN libraries from which the initial build stage starts. This stage would:</p>

<ul>
  <li>Install the opencv deps</li>
  <li>Build and install python</li>
  <li>Create a virtualenv to install the python deps and opencv bindings</li>
  <li>Download and compile the opencv source with CUDA enabled.</li>
</ul>

<p>To build python I utilise a custom script which install the deps and build it from source. Then I declared an env variable for the virtualenv path and install the pip deps:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">...

ENV <span class="nv">VIRTUAL_ENV</span><span class="o">=</span>/opt/venv
ENV <span class="nv">PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$VIRTUAL_ENV</span><span class="s2">/bin:</span><span class="nv">$PATH</span><span class="s2">"</span>

RUN /usr/local/bin/python <span class="nt">-m</span> venv <span class="k">${</span><span class="nv">VIRTUAL_ENV</span><span class="k">}</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
  pip <span class="nt">--no-cache-dir</span> <span class="nb">install</span> <span class="nt">--upgrade</span> pip setuptools <span class="o">&amp;&amp;</span> <span class="se">\</span>
  pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">--upgrade</span> <span class="s2">"cmake&gt;=3.13.2"</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
  pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> numpy <span class="o">&amp;&amp;</span> <span class="se">\</span>
  pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> imutils
...</code></pre></figure>

<p>The virtualenv can be copied during the second stage of the multi-stage build.</p>

<p>To build OpenCV with CUDA support, we need to enable the following CMake flags:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">...
<span class="nt">-D</span> <span class="nv">WITH_CUDA</span><span class="o">=</span>ON <span class="se">\</span>
<span class="nt">-D</span> <span class="nv">WITH_CUDNN</span><span class="o">=</span>ON <span class="se">\</span>
<span class="nt">-D</span> <span class="nv">OPENCV_DNN_CUDA</span><span class="o">=</span>ON <span class="se">\</span>
<span class="nt">-D</span> <span class="nv">ENABLE_FAST_MATH</span><span class="o">=</span>1 <span class="se">\</span>
<span class="nt">-D</span> <span class="nv">CUDA_FAST_MATH</span><span class="o">=</span>1 <span class="se">\</span>
<span class="nt">-D</span> <span class="nv">CUDA_ARCH_BIN</span><span class="o">=</span>6.1 <span class="se">\</span>
...</code></pre></figure>

<p>The <strong>CUDA_ARCH_BIN</strong> is set to a fixed value as the default includes older compute capability such as 35 which will be deprecated and also slows down the build. My initial understanding is that setting it to a lower value means that it will be compatible with later versions of GPU?</p>

<p>The complete CMake config becomes:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">...

cmake <span class="nt">-D</span> <span class="nv">CMAKE_BUILD_TYPE</span><span class="o">=</span>RELEASE <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">CMAKE_INSTALL_PREFIX</span><span class="o">=</span>/installed <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">PYTHON_EXECUTABLE</span><span class="o">=</span><span class="si">$(</span>which python<span class="si">)</span> <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">INSTALL_PYTHON_EXAMPLES</span><span class="o">=</span>OFF <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">OPENCV_GENERATE_PKGCONFIG</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">BUILD_opencv_python3</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">HAVE_opencv_python3</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">OPENCV_CUDA_FORCE_BUILTIN_CMAKE_MODULE</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">WITH_CUDA</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">WITH_CUDNN</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">OPENCV_DNN_CUDA</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">ENABLE_FAST_MATH</span><span class="o">=</span>1 <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">CUDA_FAST_MATH</span><span class="o">=</span>1 <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">CUDA_ARCH_BIN</span><span class="o">=</span>6.1 <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">OPENCV_ENABLE_NONFREE</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">WTIH_CUBLAS</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">WITH_V4L</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">BUILD_EXAMPLES</span><span class="o">=</span>ON <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">INSTALL_C_EXAMPLES</span><span class="o">=</span>OFF <span class="se">\</span>
	<span class="nt">-D</span> <span class="nv">OPENCV_EXTRA_MODULES_PATH</span><span class="o">=</span>/opencv_contrib/modules ..</code></pre></figure>

<p>Once compiled successfully, we symlink the opencv libs into the <code class="language-plaintext highlighter-rouge">site-packages</code> directory of the python virtualenv:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="nb">ln</span> <span class="nt">-s</span> /installed/lib/python<span class="k">${</span><span class="nv">PYVER</span><span class="k">}</span>/site-packages/cv2/python-<span class="k">${</span><span class="nv">PYVER</span><span class="k">}</span>/cv2.cpython-<span class="k">${</span><span class="nv">CPYTHON</span><span class="k">}</span><span class="nt">-x86_64-linux-gnu</span>.so <span class="nv">$VIRTUAL_ENV</span>/lib/python<span class="k">${</span><span class="nv">PYVER</span><span class="k">}</span>/site-packages/cv2.so
</pre></td></tr></tbody></table></code></pre></figure>

<p>The second stage of the GPU build involves copying the build artifacts from the previous stage into a new image that has the required deps installed. I used the <strong>cudnn8-runtime</strong> image as it has CUDNN and CUDA prebuilt.</p>

<p>For this stage, I ran the custom scripts to install python and the required OpenCV deps. Then I copy the built OpenCV artifacts and the virtualenv across. Assuming the first stage is called <code class="language-plaintext highlighter-rouge">builder</code>:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">ENV <span class="nv">VIRTUAL_ENV</span><span class="o">=</span>/opt/venv
ENV <span class="nv">PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$VIRTUAL_ENV</span><span class="s2">/bin:</span><span class="nv">$PATH</span><span class="s2">"</span>
...

COPY <span class="nt">--from</span><span class="o">=</span>builder /installed /installed

COPY <span class="nt">--from</span><span class="o">=</span>builder /opt/venv /opt/venv</code></pre></figure>

<p>Note that we still need to declare and append the virtual env path to the system path globally for virtualenv to work across images.</p>

<p>To support C++ compilation, we need to symlink the generated pkg-config file from the OpenCV compilation into the <strong>/usr/share/pkgconfig</strong>. We also need to create an entry in <strong>/etc/ld.so.conf.d/opencv4.conf</strong> so that compiled executables can locate the shared object libraries during load:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">cd</span> /usr/share/pkgconfig <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">ln</span> <span class="nt">-s</span> /installed/lib/pkgconfig/opencv4.pc opencv4.pc <span class="o">&amp;&amp;</span> <span class="se">\</span>
<span class="nb">echo</span> <span class="s2">"/installed/lib"</span> <span class="o">&gt;&gt;</span> /etc/ld.so.conf.d/opencv4.conf <span class="o">&amp;&amp;</span> <span class="se">\</span>
ldconfig</code></pre></figure>

<p>The ‘/installed’ directory is where the opencv built artifacts are located and the <code class="language-plaintext highlighter-rouge">opencv4.pc</code> file is generated when we enabled <code class="language-plaintext highlighter-rouge">-D OPENCV_GENERATE_PKGCONFIG=ON</code> in the CMake config.</p>

<p>The final image is approx 6.28 GB uncompressed and about 2.78 GB after upload to docker hub.</p>

<p>To run a CUDA image locally using the host GPU, you would need to have the <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker">nvidia container runtime</a> installed and working first.</p>

<p>I used the following <a href="https://pyimagesearch.com/2020/02/03/how-to-use-opencvs-dnn-module-with-nvidia-gpus-cuda-and-cudnn/">OpenCV DNN GPU example</a> to test if the image works locally by mounting the directory of the example code into a running container and running the example:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker run <span class="nt">-it</span> <span class="nt">--rm</span> <span class="se">\</span>
  <span class="nt">-v</span> ./opencv-dnn-gpu:/opencv-dnn-gpu <span class="se">\</span>
  <span class="nt">--runtime</span> nvidia <span class="se">\</span>
  <span class="nt">--gpus</span> all m1l0/opencv:4.5.5-cuda11.8.0-cudnn8-python3.10.9-ubuntu22.04 /bin/bash


<span class="c"># from within running container</span>
<span class="nb">cd</span> /opencv-dnn-gpu

python ssd_object_detection.py <span class="nt">--prototxt</span> MobileNetSSD_deploy.prototxt <span class="se">\</span>
  <span class="nt">--model</span> MobileNetSSD_deploy.caffemodel <span class="se">\</span>
  <span class="nt">--input</span> guitar.mp4 <span class="nt">--output</span> output2.avi <span class="se">\</span>
  <span class="nt">--display</span> 0 <span class="se">\</span>
  <span class="nt">--use-gpu</span> 1</code></pre></figure>

<p>If OpenCV is compiled properly, the above should run and generate the following:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>INFO] setting preferable backend and target to CUDA...
<span class="o">[</span>INFO] accessing video stream...
<span class="o">[</span>INFO] elasped <span class="nb">time</span>: 4.54
<span class="o">[</span>INFO] approx. FPS: 54.38</code></pre></figure>

<p>Note that we are able to obtain at least 54 FPS for object detection which is impressive.</p>

<h3 id="issues-during-build">Issues during Build</h3>

<h4 id="forward-compatibility-was-attempted-on-non-supported-hw">Forward compatibility was attempted on non supported HW</h4>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">  cv2.error: OpenCV<span class="o">(</span>4.5.5<span class="o">)</span> /opencv/modules/dnn/src/cuda4dnn/csl/memory.hpp:54: error: <span class="o">(</span><span class="nt">-217</span>:Gpu API call<span class="o">)</span> forward compatibility was attempted on non supported HW <span class="k">in function</span> <span class="s1">'ManagedPtr'</span></code></pre></figure>

<p>The nvidia container runtime is dependent on the host’s nvidia driver version. In this instance my driver is set to <code class="language-plaintext highlighter-rouge">470</code> but I’m trying to run CUDA 11.8 which requires driver version of <code class="language-plaintext highlighter-rouge">520</code> and above. I updated the host driver to <code class="language-plaintext highlighter-rouge">525</code> and the issue was resolved.</p>

<h4 id="could-not-load-library-libcudnn_cnn_inferso8">Could not load library libcudnn_cnn_infer.so.8</h4>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"> Could not load library libcudnn_cnn_infer.so.8. Error: libnvrtc.so</code></pre></figure>

<p>This error occured during the inference stage when calling <code class="language-plaintext highlighter-rouge">network.predict</code> in the python script.</p>

<p>Running <code class="language-plaintext highlighter-rouge">apt-get -y install cuda-nvrtc-11-8 cuda-nvrtc-dev-11-8</code> solves the issue</p>

<h3 id="remaining-tasks--improvements">Remaining Tasks / Improvements</h3>

<p>Additional tasks / improvements could include:</p>

<ul>
  <li>
    <p>Updating the Github Action workflow to publish the images to dockerhub</p>
  </li>
  <li>
    <p>Automate the image security scan process. Currently this is done locally via <code class="language-plaintext highlighter-rouge">docker scan</code></p>
  </li>
</ul>

<p>The built images can be found at <a href="https://hub.docker.com/r/m1l0/opencv" target="_blank">OpenCV dockerhub images</a>.</p>

<p>H4ppy H4ck1ng !!!</p>

</article>





      </div>
    </div>
  </div>

  <footer class="footer">
  <div class="p2 wrap">
    
      <div class="social-icons">
  <div class="">
    
      <a class="fa fa-github fa-lg" href="https://github.com/cheeyeo" target="_blank"></a>
    
    <a class="fa fa-rss fa-lg" href="https://www.cheeyeo.dev/feed.xml" target="_blank"></a>
    
    
    
      <a class="fa fa-envelope fa-lg" href="mailto:f/mnqwaypk"></a>
    
    
      <a class="fa fa-linkedin fa-lg" href="https://www.linkedin.com/in/cheeyeo" target="_blank"></a>
    
  </div>
</div>

    

    <div class="measure mt1 center">
      <strong>© 2023 Chee Yeo</strong><br/>
      <small>
        Built using the Pixll theme available on <a href="https://github.com/johno/pixyll" target="_blank">Github</a>.
      </small>
    </div>
  </div>
</footer>



</body>
</html>
